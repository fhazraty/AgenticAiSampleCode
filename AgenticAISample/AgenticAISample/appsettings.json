{
  "Agent": {
    "Provider": "OllamaHttp", 
    "Model": "llama3.1:8b-instruct",
    "SystemPrompt": "You are a helpful, concise local assistant.",
    "MaxTokens": 512,
    "Temperature": 0.3
  },
  "Ollama": {
    "BaseUrl": "http://localhost:11434"
  },
  "ProcessLlm": {
    "ExecutablePath": "llama.exe",
    "ArgsTemplate": "--model \"{MODEL_PATH}\" --prompt \"{PROMPT}\" --n-predict {MAX_TOKENS} --temp {TEMPERATURE}",
    "ModelPath": "models\\llama.gguf"
  },
  "Sql": {
    "ConnectionString": "Server=localhost;Database=master;Trusted_Connection=True;TrustServerCertificate=True;"
  },
  "Memory": {
    "StorePath": "memory\\agent_memory.json",
    "MaxMessages": 20
  },
  "Reports": {
    "OutputDir": "reports"
  }
}

